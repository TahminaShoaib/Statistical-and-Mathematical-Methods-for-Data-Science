nn$result.matrix
plot(nn)
library(neuralnet)
nn <- neuralnet(Class ~ Cl.thickness+Cell.size+Cell.shape,
data=trainData, hidden=c(2,1), linear.output=TRUE, threshold=0.01)
nn$result.matrix
plot(nn)
#Test the resulting output
temp_test <- subset(testData, select = c("Cl.thickness","Cell.size", "Cell.shape"))
head(temp_test)
nn.results <- compute(nn, temp_test)
results <- data.frame(actual = testData$Class, prediction = nn.results$net.result)
y_pred_num <- ifelse(results$prediction.1 > results$prediction.2, 0, 1)
y_pred <- factor(y_pred_num, levels=c(0, 1))
y_pred
y_act <- testData$Class
mean(y_pred == y_act)
table(y_act,y_pred)
data(Ionosphere, package="mlbench")
ip <- Ionosphere[complete.cases(Ionosphere), ]
for(i in 1:9) {
ip[, i] <- as.numeric(as.character(ip[, i]))
}
ip$Class <- ifelse(ip$Class == "good", 1, 0)
ip$Class <- factor(ip$Class, levels = c(0, 1))
# Prep Training and Test data.
library(caret)
'%ni%' <- Negate('%in%')  # define 'not in' func
options(scipen=999)  # prevents printing scientific notations.
set.seed(100)
trainDataIndex <- createDataPartition(ip$Class, p=0.7, list = F)
trainData <- ip[trainDataIndex, ]
testData <- ip[-trainDataIndex, ]
table(trainData$Class)
#Neural Network
library(neuralnet)
nn <- neuralnet(Class ~ V5+V3+V27+V7+V8, data=trainData, hidden=c(2,1), linear.output=TRUE, threshold=0.01)
nn$result.matrix
plot(nn)
#Test the resulting output
temp_test <- subset(testData, select = c("V5","V3", "V27", "V7", "V8"))
head(temp_test)
nn.results <- compute(nn, temp_test)
results <- data.frame(actual = testData$Class, prediction = nn.results$net.result)
results
y_pred_num <- ifelse(results$prediction.1 > results$prediction.2, 0, 1)
y_pred <- factor(y_pred_num, levels=c(0, 1))
y_pred
y_act <- testData$Class
mean(y_pred == y_act)
table(y_act,y_pred)
# Load data
# install.packages('mlbench')
data(BreastCancer, package="mlbench")
bc <- BreastCancer[complete.cases(BreastCancer), ]  # keep complete rows
# remove id column
bc <- bc[,-1]
# convert to numeric
for(i in 1:9) {
bc[, i] <- as.numeric(as.character(bc[, i]))
}
# Change Y values to 1's and 0's
bc$Class <- ifelse(bc$Class == "malignant", 1, 0)
bc$Class <- factor(bc$Class, levels = c(0, 1))
# Prep Training and Test data.
library(caret)
'%ni%' <- Negate('%in%')  # define 'not in' func
options(scipen=999)  # prevents printing scientific notations.
set.seed(100)
trainDataIndex <- createDataPartition(bc$Class, p=0.7, list = F)
trainData <- bc[trainDataIndex, ]
testData <- bc[-trainDataIndex, ]
# Class distribution of train data
table(trainData$Class)
set.seed(100)
down_train <- downSample(x = trainData[, colnames(trainData) %ni% "Class"],
y = trainData$Class)
table(down_train$Class)
# Up Sample (optional)
set.seed(100)
up_train <- upSample(x = trainData[, colnames(trainData) %ni% "Class"],
y = trainData$Class)
table(up_train$Class)
logitmod <- glm(Class ~., family = "binomial", data=down_train)
library(MASS)
steplogitmod <- stepAIC(logitmod, trace = FALSE)
coef(steplogitmod)
summary(logitmod)
library(MASS)
steplogitmod <- stepAIC(logitmod, trace = FALSE)
coef(steplogitmod)
summary(logitmod)
pred <- predict(logitmod, newdata = testData, type = "response")
y_pred_num <- ifelse(pred > 0.5, 1, 0)
y_pred <- factor(y_pred_num, levels=c(0, 1))
y_act <- testData$Class
# Accuracy
mean(y_pred == y_act)
pred <- predict(steplogitmod, newdata = testData, type = "response")
y_pred_num <- ifelse(pred > 0.5, 1, 0)
y_pred <- factor(y_pred_num, levels=c(0, 1))
y_act <- testData$Class
# Accuracy
mean(y_pred == y_act)
data(BreastCancer, package="mlbench")
bc <- BreastCancer[complete.cases(BreastCancer), ]
# remove id column
bc <- bc[,-1]
for(i in 1:9) {
bc[, i] <- as.numeric(as.character(bc[, i]))
}
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(bc[,1:9], bc[,35], sizes=c(1:9), rfeControl=control)
# summarize the results
print(results)
# list the chosen features
predictors(results)
# plot the results
plot(results, type=c("g", "o"))
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(bc[,1:9], bc[,9], sizes=c(1:9), rfeControl=control)
# summarize the results
print(results)
# list the chosen features
predictors(results)
# plot the results
plot(results, type=c("g", "o"))
bc$Class <- ifelse(bc$Class == "malignant", 1, 0)
bc$Class <- factor(bc$Class, levels = c(0, 1))
scaleddata<-scale(bc)
bc$Class <- ifelse(bc$Class == "malignant", 1, 0)
bc$Class <- factor(bc$Class, levels = c(0, 1))
library(caret)
'%ni%' <- Negate('%in%')  # define 'not in' func
options(scipen=999)  # prevents printing scientific notations.
set.seed(100)
trainDataIndex <- createDataPartition(bc$Class, p=0.7, list = F)
trainData <- bc[trainDataIndex, ]
testData <- bc[-trainDataIndex, ]
View(bc)
library(neuralnet)
nn <- neuralnet(Class ~ Mitoses,
data=trainData, hidden=c(2,1), linear.output=TRUE, threshold=0.01)
nn$result.matrix
plot(nn)
library(neuralnet)
nn <- neuralnet(Class ~ Mitoses,
data=trainData, hidden=c(1,1), linear.output=TRUE, threshold=0.01)
nn$result.matrix
library(neuralnet)
nn <- neuralnet(Class ~ Cl.thickness+Cell.size+Cell.shape,
data=trainData, hidden=c(2,1), linear.output=TRUE, threshold=0.01)
nn$result.matrix
plot(nn)
# install.packages('mlbench')
data(Ionosphere, package="mlbench")
ip <- Ionosphere[complete.cases(Ionosphere), ]
# convert to numeric
for(i in 1:9) {
ip[, i] <- as.numeric(as.character(ip[, i]))
}
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(ip[,1:34], ip[,35], sizes=c(1:34), rfeControl=control)
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(ip[,1:34], ip[,35], sizes=c(1:34), rfeControl=control)
# summarize the results
print(results)
# list the chosen features
predictors(results)
# plot the results
plot(results, type=c("g", "o"))
ip$Class <- ifelse(ip$Class == "good", 1, 0)
ip$Class <- factor(ip$Class, levels = c(0, 1))
# Prep Training and Test data.
library(caret)
'%ni%' <- Negate('%in%')  # define 'not in' func
options(scipen=999)  # prevents printing scientific notations.
set.seed(100)
trainDataIndex <- createDataPartition(ip$Class, p=0.7, list = F)
trainData <- ip[trainDataIndex, ]
testData <- ip[-trainDataIndex, ]
# Class distribution of train data
table(trainData$Class)
library(neuralnet)
nn <- neuralnet(Class ~ V5+V3+V27+V7+V8,
data=trainData, hidden=c(2,1), linear.output=TRUE, threshold=0.01)
nn$result.matrix
plot(nn)
#Test the resulting output
temp_test <- subset(testData, select = c("V5","V3", "V27", "V7", "V8"))
head(temp_test)
nn.results <- compute(nn, temp_test)
results <- data.frame(actual = testData$Class, prediction = nn.results$net.result)
results
y_pred_num <- ifelse(results$prediction.1 > results$prediction.2, 0, 1)
y_pred <- factor(y_pred_num, levels=c(0, 1))
y_pred
y_act <- testData$Class
mean(y_pred == y_act)
table(y_act,y_pred)
X_train = as.matrix(read.table('train2_5.txt'))
Y_train = as.matrix(read.table('train2_5Labels.txt'))
X_test = as.matrix(read.table('test2_5.txt'))
Y_test = as.matrix(read.table('test2_5Labels.txt'))
# Find the regression coefficients
regressionCoefficients <- function(X, Y, lambda){
add_one_matrix <- cbind(new_col=1, X)
transpose <- t(add_one_matrix)
a <- nrow(transpose)
iden <- diag(a)
new_matrix <- transpose%*%add_one_matrix
mult <- lambda*iden
sum <- new_matrix + mult
inverse_matrix <- solve(sum)
mult_new <- transpose%*%Y
final <- inverse_matrix%*%mult_new
#returnValue(final)
}
# Finding the prediction values
predictions <- function(testX,regressionCoefficients){
add_one_matrix <- cbind(new_col=1, testX)
predicted_labels <- add_one_matrix%*%regressionCoefficients
}
# Finding the confusion matrix
Matrix <- function(prediction,actualLabels){
TP=FP=TN=FN=0
for(i in seq_len(nrow(actualLabels)))
if(prediction[i]==2 && actualLabels[i]==2){
TP <- TP + 1
}else if(prediction[i]==5 && actualLabels[i]==5){
TN <- TN + 1
}else if(prediction[i]==2 && actualLabels[i]==5){
FP <- FP + 1
}else if(prediction[i]==5 && actualLabels[i]==2){
FN <- FN + 1
}
CM <- list("TP" = TP, "FP" = FP, "TN" = TN, "FN" = FN)
return(CM)
}
# Input data
X_train = as.matrix(read.table('train2_5.txt'))
Y_train = as.matrix(read.table('train2_5Labels.txt'))
X_test = as.matrix(read.table('test2_5.txt'))
Y_test = as.matrix(read.table('test2_5Labels.txt'))
setwd("E:/FAST/Semester-II/Statistical and Mathematical Methods for Data Science/Assignments/Assignment-6")
# Input data
X_train = as.matrix(read.table('train2_5.txt'))
Y_train = as.matrix(read.table('train2_5Labels.txt'))
X_test = as.matrix(read.table('test2_5.txt'))
Y_test = as.matrix(read.table('test2_5Labels.txt'))
#print(weights)
#print(i)
trainGradientDescent <- function(X, Y, learningRate, momentum){
set.seed(257)
add_one_matrix <- cbind(new_col=1, X)
weights <- rnorm(n = ncol(add_one_matrix), m=1)
Change_Weights <- matrix(0, ncol(add_one_matrix),1)
for(epoch in 1:100){
for(i in seq_len(nrow(add_one_matrix))){
r <- add_one_matrix[i,]
pred <- r%*%weights
#momentum <- 0
#learningRate <- 0.001
y <- Y[i,]
diff <- y - pred
a <- momentum*Change_Weights
b <- learningRate*diff
c <- b%*%r
c <- t(c)
Change_Weights <- (a) + (c)
weights <- weights + Change_Weights
}
}
return(weights)
}
testGradientDescent <- function (testX,regressionCoefficients){
add_one_matrix <- cbind(new_col=1, testX)
prediction <- add_one_matrix%*%weights
}
Matrix <- function(prediction,actualLabels){
TP=FP=TN=FN=0
for(i in seq_len(nrow(actualLabels)))
if(prediction[i]==2 && actualLabels[i]==2){
TP <- TP + 1
}else if(prediction[i]==5 && actualLabels[i]==5){
TN <- TN + 1
}else if(prediction[i]==2 && actualLabels[i]==5){
FP <- FP + 1
}else if(prediction[i]==5 && actualLabels[i]==2){
FN <- FN + 1
}
CM <- list("TP" = TP, "FP" = FP, "TN" = TN, "FN" = FN)
return(CM)
}
weights <- trainGradientDescent(X_train, Y_train, 0.1,0.5)
weights <- trainGradientDescent(X_train, Y_train, 0.001,0)
predicted_labels <- 0
for(i in seq_len(nrow(predictions))){
if(abs(predictions[i]-2)<abs(predictions[i]-5)){
predicted_labels[i] <- 2
}else{
predicted_labels[i] <- 5
}
}
predictions <- testGradientDescent(X_train, weights)
predicted_labels <- 0
for(i in seq_len(nrow(predictions))){
if(abs(predictions[i]-2)<abs(predictions[i]-5)){
predicted_labels[i] <- 2
}else{
predicted_labels[i] <- 5
}
}
CM <- Matrix(predicted_labels, Y_train)
View(CM)
CM_train <- Matrix(predicted_labels, Y_train)
predictions <- testGradientDescent(X_test, weights)
predicted_labels <- 0
for(i in seq_len(nrow(predictions))){
if(abs(predictions[i]-2)<abs(predictions[i]-5)){
predicted_labels[i] <- 2
}else{
predicted_labels[i] <- 5
}
}
CM_test <- Matrix(predicted_labels, Y_test)
View(CM_test)
View(CM_train)
CM_train[1]
CM_train[2]
CM_train[3]
CM_train[4]
nrow(Y_train['2'])
nrow(Y_train = 2)
nrow(Y_train = '2')
twoClass = Y_train==2
count2 <- nrow(twoClass)
count2
twoClass = Y_train=='2'
count2 <- nrow(twoClass)
count2
twoClass = Y_train==2
twoClass
twoClass = Y_train==2
twoDat = Y_train[twoClass,]
nrow(twoDat)
twoDat
count(twoDat)
nrow(Y_train[twoClass,])
Y_train == 2
nrow(Y_train==2)
twoClass
nrow(twoClass==TRUE)
apply(Y_train, 2, function(x) length(unique(x)))
library(plyr)
View(Y_train)
count(Y_train, "V1")
q <- count(Y_train, "V1")
View(q)
q[1]
row_count(Y_train, count = 2, append = FALSE)
View(Y_train)
sum(Y_train$V1==2)
sum(Y_train==2)
TP <- CM_train[1]
TN <- CM_train[3]
positveClass <- sum(Y_train==2)
negativeClass <- sum(Y_train==5)
BACAccuracy <- ((TP/positveClass)+(TN/negativeClass))/2
TP/positveClass
as.numeric(TP)
as.numeric(TP)/positveClass
TP <- as.numeric(CM_train[1])
TN <- as.numeric(CM_train[3])
TP/positveClass
TN/negativeClass
TP/positveClass + TN/negativeClass
a <- TP/positveClass + TN/negativeClass
a/2
BACAccuracy <- ((TP/positveClass)+(TN/negativeClass))/2
BACAccuracy
TP <- as.numeric(CM_test[1])
TN <- as.numeric(CM_test[3])
positveClass <- sum(Y_test==2)
negativeClass <- sum(Y_test==5)
BACAccuracy <- ((TP/positveClass)+(TN/negativeClass))/2
BACAccuracy
weights <- trainGradientDescent(X_train, Y_train, 0.7,0.9)
predictions <- testGradientDescent(X_train, weights)
predicted_labels <- 0
for(i in seq_len(nrow(predictions))){
if(abs(predictions[i]-2)<abs(predictions[i]-5)){
predicted_labels[i] <- 2
}else{
predicted_labels[i] <- 5
}
}
predictions <- testGradientDescent(X_test, weights)
predicted_labels <- 0
for(i in seq_len(nrow(predictions))){
if(abs(predictions[i]-2)<abs(predictions[i]-5)){
predicted_labels[i] <- 2
}else{
predicted_labels[i] <- 5
}
}
weights <- trainGradientDescent(X_train, Y_train, 0.0001,0.1)
predictions <- testGradientDescent(X_train, weights)
predicted_labels <- 0
for(i in seq_len(nrow(predictions))){
if(abs(predictions[i]-2)<abs(predictions[i]-5)){
predicted_labels[i] <- 2
}else{
predicted_labels[i] <- 5
}
}
CM_train <- Matrix(predicted_labels, Y_train)
TP <- as.numeric(CM_train[1])
TN <- as.numeric(CM_train[3])
positveClass <- sum(Y_train==2)
negativeClass <- sum(Y_train==5)
BACAccuracy <- ((TP/positveClass)+(TN/negativeClass))/2
View(CM_train)
BACAccuracy
predictions <- testGradientDescent(X_test, weights)
predicted_labels <- 0
for(i in seq_len(nrow(predictions))){
if(abs(predictions[i]-2)<abs(predictions[i]-5)){
predicted_labels[i] <- 2
}else{
predicted_labels[i] <- 5
}
}
CM_test <- Matrix(predicted_labels, Y_test)
View(CM_test)
TP <- as.numeric(CM_test[1])
TN <- as.numeric(CM_test[3])
positveClass <- sum(Y_test==2)
negativeClass <- sum(Y_test==5)
BACAccuracy <- ((TP/positveClass)+(TN/negativeClass))/2
weights <- trainGradientDescent(X_train, Y_train, 0.001,0.1)
predictions <- testGradientDescent(X_train, weights)
predicted_labels <- 0
for(i in seq_len(nrow(predictions))){
if(abs(predictions[i]-2)<abs(predictions[i]-5)){
predicted_labels[i] <- 2
}else{
predicted_labels[i] <- 5
}
}
CM_train <- Matrix(predicted_labels, Y_train)
View(CM_train)
TP <- as.numeric(CM_train[1])
TN <- as.numeric(CM_train[3])
positveClass <- sum(Y_train==2)
negativeClass <- sum(Y_train==5)
BACAccuracy <- ((TP/positveClass)+(TN/negativeClass))/2
predictions <- testGradientDescent(X_test, weights)
predicted_labels <- 0
for(i in seq_len(nrow(predictions))){
if(abs(predictions[i]-2)<abs(predictions[i]-5)){
predicted_labels[i] <- 2
}else{
predicted_labels[i] <- 5
}
}
CM_test <- Matrix(predicted_labels, Y_test)
View(CM_test)
TP <- as.numeric(CM_test[1])
TN <- as.numeric(CM_test[3])
positveClass <- sum(Y_test==2)
negativeClass <- sum(Y_test==5)
BACAccuracy <- ((TP/positveClass)+(TN/negativeClass))/2
weights <- trainGradientDescent(X_train, Y_train, 0.001,0.9)
predictions <- testGradientDescent(X_train, weights)
predicted_labels <- 0
for(i in seq_len(nrow(predictions))){
if(abs(predictions[i]-2)<abs(predictions[i]-5)){
predicted_labels[i] <- 2
}else{
predicted_labels[i] <- 5
}
}
CM_train <- Matrix(predicted_labels, Y_train)
# BAC Accuracy
TP <- as.numeric(CM_train[1])
TN <- as.numeric(CM_train[3])
positveClass <- sum(Y_train==2)
negativeClass <- sum(Y_train==5)
BACAccuracy <- ((TP/positveClass)+(TN/negativeClass))/2
predictions <- testGradientDescent(X_test, weights)
predicted_labels <- 0
for(i in seq_len(nrow(predictions))){
if(abs(predictions[i]-2)<abs(predictions[i]-5)){
predicted_labels[i] <- 2
}else{
predicted_labels[i] <- 5
}
}
CM_test <- Matrix(predicted_labels, Y_test)
# BAC Accuracy
TP <- as.numeric(CM_test[1])
TN <- as.numeric(CM_test[3])
positveClass <- sum(Y_test==2)
negativeClass <- sum(Y_test==5)
BACAccuracy <- ((TP/positveClass)+(TN/negativeClass))/2
View(CM_test)
View(CM_train)
